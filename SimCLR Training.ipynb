{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RHR285hmt1EU"
   },
   "source": [
    "#SimCLR Training for IDD Dataset\n",
    "\n",
    "In this notebook, we will train a SimCLR backbone with raw data from the Indian Driving Dataset (50.5k Images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4370,
     "status": "ok",
     "timestamp": 1682862468519,
     "user": {
      "displayName": "Vijayasri Iyer",
      "userId": "15995189966955202611"
     },
     "user_tz": -330
    },
    "id": "DCjcWzdpTZUL",
    "outputId": "8ecec0d5-affc-4445-d842-82e224c2b362"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 591,
     "status": "ok",
     "timestamp": 1682862483643,
     "user": {
      "displayName": "Vijayasri Iyer",
      "userId": "15995189966955202611"
     },
     "user_tz": -330
    },
    "id": "HG5hA624TaIt",
    "outputId": "5247c3bf-50ba-4738-97f9-178fffa6c0a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/UNI-AMRITA-SEM4/unsupervised-mtl-idd\n"
     ]
    }
   ],
   "source": [
    "%cd drive/MyDrive/UNI-AMRITA-SEM4/unsupervised-mtl-idd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3283,
     "status": "ok",
     "timestamp": 1682862491045,
     "user": {
      "displayName": "Vijayasri Iyer",
      "userId": "15995189966955202611"
     },
     "user_tz": -330
    },
    "id": "F7vS6b4S7yii",
    "outputId": "b995f509-755e-4f83-b0db-8f859cab9570"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.10/dist-packages (2.0.2)\n",
      "Requirement already satisfied: lightly in /usr/local/lib/python3.10/dist-packages (1.4.3)\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2023.4.0)\n",
      "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (23.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.5.0)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (0.11.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2.0.0+cu118)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (0.8.0)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (1.22.4)\n",
      "Requirement already satisfied: hydra-core>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from lightly) (1.3.2)\n",
      "Requirement already satisfied: lightly-utils~=0.0.0 in /usr/local/lib/python3.10/dist-packages (from lightly) (0.0.2)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from lightly) (1.16.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from lightly) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from lightly) (2.8.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from lightly) (2.27.1)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from lightly) (0.15.1+cu118)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.10/dist-packages (from lightly) (1.26.15)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (3.8.4)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.0.0->lightly) (4.9.3)\n",
      "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.0.0->lightly) (2.3.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from lightly-utils~=0.0.0->lightly) (8.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->lightly) (3.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->lightly) (2.0.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch_lightning) (3.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch_lightning) (1.11.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch_lightning) (3.12.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch_lightning) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch_lightning) (2.0.0)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch_lightning) (16.0.2)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch_lightning) (3.25.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (23.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (6.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->pytorch_lightning) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->pytorch_lightning) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch_lightning lightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 1117,
     "status": "ok",
     "timestamp": 1682861519414,
     "user": {
      "displayName": "Vijayasri Iyer",
      "userId": "15995189966955202611"
     },
     "user_tz": -330
    },
    "id": "RuwLbiBvVNXr"
   },
   "outputs": [],
   "source": [
    "#!gdown https://drive.google.com/uc?id=1ds6LQNbyXQqWyIRaPeXlQq1xj94GhFPU\n",
    "#!unzip idd-raw-data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 7391,
     "status": "ok",
     "timestamp": 1682862504174,
     "user": {
      "displayName": "Vijayasri Iyer",
      "userId": "15995189966955202611"
     },
     "user_tz": -330
    },
    "id": "IegMKyM6t1EX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import pytorch_lightning as pl\n",
    "import lightly\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import normalize\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-Ly_8Gkt1EY"
   },
   "source": [
    "## Configuration\n",
    "\n",
    "We set some configuration parameters for our experiment.\n",
    "Feel free to change them and analyze the effect.\n",
    "\n",
    "The default configuration with a batch size of 256 and input resolution of 128\n",
    "requires 6GB of GPU memory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 500,
     "status": "ok",
     "timestamp": 1682862596826,
     "user": {
      "displayName": "Vijayasri Iyer",
      "userId": "15995189966955202611"
     },
     "user_tz": -330
    },
    "id": "W-DhMRnht1EZ"
   },
   "outputs": [],
   "source": [
    "num_workers = 8\n",
    "batch_size = 16\n",
    "seed = 1\n",
    "max_epochs = 20\n",
    "input_size = 512\n",
    "num_ftrs = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e74fq79-t1EZ"
   },
   "source": [
    "Let's set the seed for our experiments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1682862603277,
     "user": {
      "displayName": "Vijayasri Iyer",
      "userId": "15995189966955202611"
     },
     "user_tz": -330
    },
    "id": "aSBjmAKKt1Ea",
    "outputId": "e38bb065-2e61-4334-fe05-6e15ad325bfe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning_fabric.utilities.seed:Global seed set to 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1682862600147,
     "user": {
      "displayName": "Vijayasri Iyer",
      "userId": "15995189966955202611"
     },
     "user_tz": -330
    },
    "id": "zOK29-Jct1Ea"
   },
   "outputs": [],
   "source": [
    "path_to_data = 'idd-raw-data/all_images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jGb6Y_Out1Eb"
   },
   "source": [
    "## Setup data augmentations and loaders\n",
    "\n",
    "The images from the dataset have been taken from above when the clothing was \n",
    "on a table, bed or floor. Therefore, we can make use of additional augmentations\n",
    "such as vertical flip or random rotation (90 degrees). \n",
    "By adding these augmentations we learn our model invariance regarding the \n",
    "orientation of the clothing piece. E.g. we don't care if a shirt is upside down\n",
    "but more about the strcture which make it a shirt.\n",
    "\n",
    "You can learn more about the different augmentations and learned invariances\n",
    "here: `lightly-advanced`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 77091,
     "status": "ok",
     "timestamp": 1682862684902,
     "user": {
      "displayName": "Vijayasri Iyer",
      "userId": "15995189966955202611"
     },
     "user_tz": -330
    },
    "id": "ZyFGnLRxt1Ec",
    "outputId": "d9a8d346-5248-4041-cab4-11b0dc712891"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "collate_fn = lightly.data.SimCLRCollateFunction(\n",
    "    input_size=input_size,\n",
    "    vf_prob=0.5,\n",
    "    rr_prob=0.5\n",
    ")\n",
    "\n",
    "# We create a torchvision transformation for embedding the dataset after \n",
    "# training\n",
    "test_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((input_size, input_size)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(\n",
    "        mean=lightly.data.collate.imagenet_normalize['mean'],\n",
    "        std=lightly.data.collate.imagenet_normalize['std'],\n",
    "    )\n",
    "])\n",
    "\n",
    "dataset_train_simclr = lightly.data.LightlyDataset(\n",
    "    input_dir=path_to_data\n",
    ")\n",
    "\n",
    "# dataset_test = lightly.data.LightlyDataset(\n",
    "#     input_dir=path_to_data,\n",
    "#     transform=test_transforms\n",
    "# )\n",
    "\n",
    "dataloader_train_simclr = torch.utils.data.DataLoader(\n",
    "    dataset_train_simclr,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "# dataloader_test = torch.utils.data.DataLoader(\n",
    "#     dataset_test,\n",
    "#     batch_size=batch_size,\n",
    "#     shuffle=False,\n",
    "#     drop_last=False,\n",
    "#     num_workers=num_workers\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tI0k6n33t1Ed"
   },
   "source": [
    "## Create the SimCLR Model\n",
    "Now we create the SimCLR model. We implement it as a PyTorch Lightning Module\n",
    "and use a ResNet-18 backbone from Torchvision. Lightly provides implementations\n",
    "of the SimCLR projection head and loss function in the `SimCLRProjectionHead`\n",
    "and `NTXentLoss` classes. We can simply import them and combine the building\n",
    "blocks in the module.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 778,
     "status": "ok",
     "timestamp": 1682862698628,
     "user": {
      "displayName": "Vijayasri Iyer",
      "userId": "15995189966955202611"
     },
     "user_tz": -330
    },
    "id": "kqudnZRlt1Ed"
   },
   "outputs": [],
   "source": [
    "from lightly.models.modules.heads import SimCLRProjectionHead\n",
    "from lightly.loss import NTXentLoss\n",
    "\n",
    "\n",
    "class SimCLRModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # create a ResNet backbone and remove the classification head\n",
    "        resnet = torchvision.models.resnet18()\n",
    "        self.backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
    "\n",
    "        hidden_dim = resnet.fc.in_features\n",
    "        self.projection_head = SimCLRProjectionHead(hidden_dim, hidden_dim, 128)\n",
    "\n",
    "        self.criterion = NTXentLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.backbone(x).flatten(start_dim=1)\n",
    "        z = self.projection_head(h)\n",
    "        return z\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        (x0, x1), _, _ = batch\n",
    "        z0 = self.forward(x0)\n",
    "        z1 = self.forward(x1)\n",
    "        loss = self.criterion(z0, z1)\n",
    "        self.log(\"train_loss_ssl\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.SGD(\n",
    "            self.parameters(), lr=6e-2, momentum=0.9, weight_decay=5e-4\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optim, max_epochs\n",
    "        )\n",
    "        return [optim], [scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKqzFpBet1Ee"
   },
   "source": [
    "We first check if a GPU is available and then train the module\n",
    "using the PyTorch Lightning Trainer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416,
     "referenced_widgets": [
      "b4ec075091d944b894f10a76d9b28769",
      "647db2dd7a8a49d2ad20a895e61982cd",
      "fec4d02039a244b7893840baf2bc20d9",
      "72814dd128ae4747aa4a79320d25ca44",
      "4dede3a55192461d94b81ca58508dceb",
      "900248f1981b4a5aa07d7189be059203",
      "63c72c0a28104d1182c60673273e0278",
      "3f1551cf149b4e84b7bb7b390e5d0392",
      "61776c21a8364d44ae9000b6cee222c5",
      "5bcfb532f5dc4e6a823d8169a6c9bcad",
      "ed185588256a48c79696a744b7702244"
     ]
    },
    "executionInfo": {
     "elapsed": 8658561,
     "status": "ok",
     "timestamp": 1682871361110,
     "user": {
      "displayName": "Vijayasri Iyer",
      "userId": "15995189966955202611"
     },
     "user_tz": -330
    },
    "id": "08E7Dpx9t1Ef",
    "outputId": "1741ad43-0919-409f-e661-76729ca8c4df"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: /content/drive/MyDrive/UNI-AMRITA-SEM4/unsupervised-mtl-idd/lightning_logs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name            | Type                 | Params\n",
      "---------------------------------------------------------\n",
      "0 | backbone        | Sequential           | 11.2 M\n",
      "1 | projection_head | SimCLRProjectionHead | 328 K \n",
      "2 | criterion       | NTXentLoss           | 0     \n",
      "---------------------------------------------------------\n",
      "11.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.5 M    Total params\n",
      "46.022    Total estimated model params size (MB)\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4ec075091d944b894f10a76d9b28769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    }
   ],
   "source": [
    "gpus = 1 if torch.cuda.is_available() else 0\n",
    "\n",
    "model = SimCLRModel()\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=max_epochs\n",
    ")\n",
    "trainer.fit(model, dataloader_train_simclr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZMGSjFgt1Ef"
   },
   "source": [
    "Next we create a helper function to generate embeddings\n",
    "from our test images using the model we just trained.\n",
    "Note that only the backbone is needed to generate embeddings,\n",
    "the projection head is only required for the training.\n",
    "Make sure to put the model into eval mode for this part!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1682872027474,
     "user": {
      "displayName": "Vijayasri Iyer",
      "userId": "15995189966955202611"
     },
     "user_tz": -330
    },
    "id": "EFe2xJ2Ct1Ef"
   },
   "outputs": [],
   "source": [
    "def generate_embeddings(model, dataloader):\n",
    "    \"\"\"Generates representations for all images in the dataloader with\n",
    "    the given model\n",
    "    \"\"\"\n",
    "\n",
    "    embeddings = []\n",
    "    filenames = []\n",
    "    with torch.no_grad():\n",
    "        for img, label, fnames in dataloader:\n",
    "            img = img.to(model.device)\n",
    "            emb = model.backbone(img).flatten(start_dim=1)\n",
    "            embeddings.append(emb)\n",
    "            filenames.extend(fnames)\n",
    "\n",
    "    embeddings = torch.cat(embeddings, 0)\n",
    "    embeddings = normalize(embeddings)\n",
    "    return embeddings, filenames\n",
    "\n",
    "\n",
    "# model.eval()\n",
    "# embeddings, filenames = generate_embeddings(model, dataloader_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ehPgIQANt1Eg"
   },
   "source": [
    "## Visualize Nearest Neighbors\n",
    " Let's look at the trained embedding and visualize the nearest neighbors for \n",
    " a few random samples.\n",
    "\n",
    " We create some helper functions to simplify the work\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KrO9mkX5t1Eg"
   },
   "outputs": [],
   "source": [
    "def get_image_as_np_array(filename: str):\n",
    "    \"\"\"Returns an image as an numpy array\n",
    "    \"\"\"\n",
    "    img = Image.open(filename)\n",
    "    return np.asarray(img)\n",
    "\n",
    "\n",
    "def plot_knn_examples(embeddings, filenames, n_neighbors=3, num_examples=6):\n",
    "    \"\"\"Plots multiple rows of random images with their nearest neighbors\n",
    "    \"\"\"\n",
    "    # lets look at the nearest neighbors for some samples\n",
    "    # we use the sklearn library\n",
    "    nbrs = NearestNeighbors(n_neighbors=n_neighbors).fit(embeddings)\n",
    "    distances, indices = nbrs.kneighbors(embeddings)\n",
    "\n",
    "    # get 5 random samples\n",
    "    samples_idx = np.random.choice(len(indices), size=num_examples, replace=False)\n",
    "\n",
    "    # loop through our randomly picked samples\n",
    "    for idx in samples_idx:\n",
    "        fig = plt.figure()\n",
    "        # loop through their nearest neighbors\n",
    "        for plot_x_offset, neighbor_idx in enumerate(indices[idx]):\n",
    "            # add the subplot\n",
    "            ax = fig.add_subplot(1, len(indices[idx]), plot_x_offset + 1)\n",
    "            # get the correponding filename for the current index\n",
    "            fname = os.path.join(path_to_data, filenames[neighbor_idx])\n",
    "            # plot the image\n",
    "            plt.imshow(get_image_as_np_array(fname))\n",
    "            # set the title to the distance of the neighbor\n",
    "            ax.set_title(f'd={distances[idx][plot_x_offset]:.3f}')\n",
    "            # let's disable the axis\n",
    "            plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMiLs0MDt1Eh"
   },
   "source": [
    "Let's do the plot of the images. The leftmost image is the query image whereas\n",
    "the ones next to it on the same row are the nearest neighbors.\n",
    "In the title we see the distance of the neigbor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C4RHCwZJt1Eh"
   },
   "outputs": [],
   "source": [
    "plot_knn_examples(embeddings, filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2CpDWO_ot1Eh"
   },
   "source": [
    "## Color Invariance\n",
    "Let's train again without color augmentation. This will force our model to \n",
    "respect the colors in the images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9rUZgP69t1Ei"
   },
   "outputs": [],
   "source": [
    "# Set color jitter and gray scale probability to 0\n",
    "new_collate_fn = lightly.data.SimCLRCollateFunction(\n",
    "    input_size=input_size,\n",
    "    vf_prob=0.5,\n",
    "    rr_prob=0.5,\n",
    "    cj_prob=0.0,\n",
    "    random_gray_scale=0.0\n",
    ")\n",
    "\n",
    "# let's update our collate method and reuse our dataloader\n",
    "dataloader_train_simclr.collate_fn = new_collate_fn\n",
    "\n",
    "# then train a new model\n",
    "model = SimCLRModel()\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=max_epochs, gpus=gpus, progress_bar_refresh_rate=100\n",
    ")\n",
    "trainer.fit(model, dataloader_train_simclr)\n",
    "\n",
    "# and generate again embeddings from the test set\n",
    "model.eval()\n",
    "embeddings, filenames = generate_embeddings(model, dataloader_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2SC6GC2Wt1Ei"
   },
   "source": [
    "other example\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mNFLqvfbt1Ei"
   },
   "outputs": [],
   "source": [
    "plot_knn_examples(embeddings, filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCGWkPQQt1Ej"
   },
   "source": [
    "What's next?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1682872035290,
     "user": {
      "displayName": "Vijayasri Iyer",
      "userId": "15995189966955202611"
     },
     "user_tz": -330
    },
    "id": "g4UjJDDVt1Ej"
   },
   "outputs": [],
   "source": [
    "# You could use the pre-trained model and train a classifier on top.\n",
    "pretrained_resnet_backbone = model.backbone\n",
    "\n",
    "# you can also store the backbone and use it in another code\n",
    "state_dict = {\n",
    "    'resnet18_parameters': pretrained_resnet_backbone.state_dict()\n",
    "}\n",
    "torch.save(state_dict, 'model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MP-x1sOXt1Ej"
   },
   "source": [
    "THIS COULD BE IN A NEW FILE (e.g. inference.py)\n",
    "\n",
    "Make sure you place the `model.pth` file in the same folder as this code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 970,
     "status": "ok",
     "timestamp": 1682872043735,
     "user": {
      "displayName": "Vijayasri Iyer",
      "userId": "15995189966955202611"
     },
     "user_tz": -330
    },
    "id": "YypCJ6L5t1Ej",
    "outputId": "3aac16fd-408f-4f3e-c61a-0319992cc7bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model in a new file for inference\n",
    "resnet18_new = torchvision.models.resnet18()\n",
    "\n",
    "# note that we need to create exactly the same backbone in order to load the weights\n",
    "backbone_new = nn.Sequential(*list(resnet18_new.children())[:-1])\n",
    "\n",
    "ckpt = torch.load('model.pth')\n",
    "backbone_new.load_state_dict(ckpt['resnet18_parameters'])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "3f1551cf149b4e84b7bb7b390e5d0392": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4dede3a55192461d94b81ca58508dceb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "5bcfb532f5dc4e6a823d8169a6c9bcad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61776c21a8364d44ae9000b6cee222c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "63c72c0a28104d1182c60673273e0278": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "647db2dd7a8a49d2ad20a895e61982cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_900248f1981b4a5aa07d7189be059203",
      "placeholder": "​",
      "style": "IPY_MODEL_63c72c0a28104d1182c60673273e0278",
      "value": "Epoch 19: 100%"
     }
    },
    "72814dd128ae4747aa4a79320d25ca44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5bcfb532f5dc4e6a823d8169a6c9bcad",
      "placeholder": "​",
      "style": "IPY_MODEL_ed185588256a48c79696a744b7702244",
      "value": " 772/772 [07:01&lt;00:00,  1.83it/s, v_num=0]"
     }
    },
    "900248f1981b4a5aa07d7189be059203": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b4ec075091d944b894f10a76d9b28769": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_647db2dd7a8a49d2ad20a895e61982cd",
       "IPY_MODEL_fec4d02039a244b7893840baf2bc20d9",
       "IPY_MODEL_72814dd128ae4747aa4a79320d25ca44"
      ],
      "layout": "IPY_MODEL_4dede3a55192461d94b81ca58508dceb"
     }
    },
    "ed185588256a48c79696a744b7702244": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fec4d02039a244b7893840baf2bc20d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f1551cf149b4e84b7bb7b390e5d0392",
      "max": 772,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_61776c21a8364d44ae9000b6cee222c5",
      "value": 772
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
